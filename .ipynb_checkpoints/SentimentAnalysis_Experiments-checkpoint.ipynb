{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shashankbhushan/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import string, re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from time import time\n",
    "from pos_sentiment_scoring import Splitter\n",
    "from pos_sentiment_scoring import POSTagger\n",
    "from pos_sentiment_scoring import DictionaryTagger\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/tweets.txt', sep = ';~;', engine='python')\n",
    "PositiveTweets = pd.read_csv('Data/tweetsPositive.txt', sep = ';~;', engine='python')\n",
    "NegativeTweets = pd.read_csv('Data/tweetsNegative.txt', sep = ';~;', engine='python')\n",
    "\n",
    "emoji_list = pd.read_csv('Data/emoji_table.txt', encoding='utf-8', index_col=0).index.values\n",
    "SentimentEmoji = pd.read_csv('Data/Emoji_classification.csv', encoding='utf-8').dropna()\n",
    "SentimentHashtags = pd.read_csv('Data/hashtags.csv', encoding='utf-8').dropna()\n",
    "\n",
    "## The test set for hillary\n",
    "hillaryTest = pd.read_csv('Hillary.csv')\n",
    "TrumpTest = pd.read_csv('Trump.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of positive and negative tweets\n",
    "sad = [':‑(', ':(', ':‑c', ':c', ':‑<', ':<', ':‑[' ,':[', ':-||', '>:[', ':{', ':@', '>:(']\n",
    "Positive = [':‑)',':)', ':-]', ':]',':-3', ':3', ':->', ':>' ,'8-)', '8)',':-}', ':}', ':o)', ':c)', ':^)' ,'=]', '=)'\n",
    "           ,':‑D', ':D', '8‑D', '8D', 'x‑D', 'xD', 'X‑D', 'XD', '=D', '=3', 'B^D']\n",
    "SentimentHashtags['HashtagSentiment'] = SentimentHashtags['HashtagSentiment'].map({'Positive':1, 'Negative':-1})\n",
    "SentimentEmoji['Sentiment'] = SentimentEmoji['Sentiment'].map({'Positive':1, 'Negative':-1, 'Neutral':0}).dropna()\n",
    "SentimentHashtags['Directed'] = SentimentHashtags['Directed'].map({'T':1, 'H':0})\n",
    "hillaryTest.Sentiment = hillaryTest.Sentiment.map({'Positive':1, 'Negative':-1, 'Neutral':0})\n",
    "TrumpTest.Sentiment = TrumpTest.Sentiment.map({'Positive':1, 'Negative':-1, 'Neutral':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5e8f55768340>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"rt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# rt - stands for retweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlemmatizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# regex for capturing tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'(\\:\\w+\\:|\\<[\\/\\\\]?3|[\\(\\)\\\\\\D|\\*\\$][\\-\\^]?[\\:\\;\\=]|[\\:\\;\\=B8][\\-\\^]?[3DOPp\\@\\$\\*\\\\\\)\\(\\/\\|])(?=\\s|[\\!\\.\\?]|$)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "stop_list = nltk.corpus.stopwords.words('english') + [\"rt\"] # rt - stands for retweet\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "# regex for capturing tweets\n",
    "reg = '(\\:\\w+\\:|\\<[\\/\\\\]?3|[\\(\\)\\\\\\D|\\*\\$][\\-\\^]?[\\:\\;\\=]|[\\:\\;\\=B8][\\-\\^]?[3DOPp\\@\\$\\*\\\\\\)\\(\\/\\|])(?=\\s|[\\!\\.\\?]|$)'\n",
    "emoticons = \"|\".join(map(re.escape, sad + Positive))\n",
    "\n",
    "emoji_pattern = re.compile(u'('\n",
    "    u'\\ud83c[\\udf00-\\udfff]|'\n",
    "    u'\\ud83d[\\udc00-\\ude4f\\ude80-\\udeff]|'\n",
    "    u'[\\u2600-\\u26FF\\u2700-\\u27BF])+', \n",
    "    re.UNICODE)\n",
    "classifier =[]\n",
    "def preprocess(tweet):\n",
    "    # only processing if the the value is a string\n",
    "    if type(tweet)!=type(2.0):\n",
    "        tweet = tweet.decode('latin-1').encode(\"utf-8\").decode('utf-8').strip()\n",
    "        tweet = tweet.lower()\n",
    "        # Removing hashtags\n",
    "        tweet = \" \".join(tweet.split('#'))\n",
    "        # Removing URLs\n",
    "        tweet = re.sub('((www\\.[^\\s]+)|(https://[^\\s]+))','',tweet)\n",
    "        tweet = re.sub('((pic\\.[^\\s]+)|(https://[^\\s]+))','',tweet)\n",
    "        tweet = re.sub(\"(http\\S+)|(https\\S+)\", '', tweet)\n",
    "        # Adding this pattern to the last cause it will remove everything after the start of a URL\n",
    "        tweet = re.sub(u'[a-zA-Z0-9./]+\\.[a-zA-Z0-9./ ]+.*$','',tweet)\n",
    "        \n",
    "        # Removing User mentions\n",
    "        tweet = re.sub('@[^\\s]+','',tweet)\n",
    "        tweet = tweet.strip('\\'\"')\n",
    "        # Removing stop words - This can be moved to count vectorization\n",
    "        # tweet  = \" \".join([word for word in tweet.split(\" \") if word not in stop_list])\n",
    "        # lemmatizing words \n",
    "        tweet = \" \".join([lemmatizer.lemmatize(word) for word in tweet.split(\" \")])\n",
    "    else:\n",
    "        tweet=''\n",
    "    return tweet\n",
    "\n",
    "def extractEmoticons(tweet):\n",
    "    # emoji = emoji_pattern.findall(tweet)\n",
    "    emoji = []\n",
    "    for emo in emoji_list:\n",
    "        if emo in tweet:\n",
    "            emoji.append(emo)\n",
    "    \n",
    "    # these are :) :-) and other stuff\n",
    "    emoticons = re.findall(reg, tweet)\n",
    "    return \" , \".join(emoji + emoticons)\n",
    "def removeEmoticons(tweet):\n",
    "    return re.sub(reg,'',tweet)\n",
    "\n",
    "#Processing the tweets\n",
    "data['processed_text'] = data.text.apply(preprocess)\n",
    "print data['processed_text']\n",
    "hillaryTest['processed_text'] = hillaryTest.processed_text.apply(preprocess)\n",
    "TrumpTest['processed_text'] = TrumpTest.processed_text.apply(preprocess)\n",
    "PositiveTweets['processed_text'] = PositiveTweets.text.apply(preprocess)\n",
    "NegativeTweets['processed_text'] = NegativeTweets.text.apply(preprocess)\n",
    "\n",
    "\n",
    "#getting the emoticons from the cleaned data\n",
    "data['emoticons'] = data['processed_text'].apply(extractEmoticons)\n",
    "\n",
    "# Removing emoticons from the text data\n",
    "data['processed_text'] = data['processed_text'].apply(removeEmoticons)\n",
    "\n",
    "#Applying sentence splitting, POS tagging, and Dictionary Tagging\n",
    "splitter = Splitter()\n",
    "postagger = POSTagger()\n",
    "dicttagger = DictionaryTagger([ 'dicts/positive.yml', 'dicts/negative.yml', \n",
    "                                    'dicts/inc.yml', 'dicts/dec.yml', 'dicts/inv.yml'])\n",
    "\n",
    "splitted_sentences = splitter.split(data['processed_text'])\n",
    "\n",
    "pos_tagged_sentences = postagger.pos_tag(splitted_sentences)\n",
    "\n",
    "dict_tagged_sentences = dicttagger.tag(pos_tagged_sentences)\n",
    "\n",
    "# Sentiment score as a result of POS & Dictionary tagging\n",
    "score = sentiment_score(dict_tagged_sentences)\n",
    "\n",
    "data = data.append(PositiveTweets).append(NegativeTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shashankbhushan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:1: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "HillaryTweets = data[data['processed_text'].str.contains('((hil.?ary)|(clinton))', case = False)]\n",
    "DonaldTweets = data[data['processed_text'].str.contains('trump', case = False)]\n",
    "\n",
    "datasets = [HillaryTweets.copy(), DonaldTweets.copy()]\n",
    "TrainSets = []\n",
    "for i, dataset in enumerate(datasets):\n",
    "    hashtags = datasets[i]['hashtags'].copy().str.split(' ').apply(pd.Series, 1).stack()\n",
    "    hashtags.index = hashtags.index.droplevel(-1)\n",
    "    datasets[i].drop('hashtags', axis=1, inplace=True)\n",
    "    hashtags.name = 'hashtags'\n",
    "    \n",
    "    datasets[i] = datasets[i].join(hashtags.str.strip())\n",
    "    \n",
    "    emoticons = datasets[i]['emoticons'].copy().str.split(' ').apply(pd.Series, 1).stack()\n",
    "    emoticons.index = emoticons.index.droplevel(-1)\n",
    "    datasets[i].drop('emoticons', axis=1, inplace=True)\n",
    "    emoticons.name = 'emoticons'\n",
    "    datasets[i] = datasets[i].join(emoticons.str.strip())\n",
    "    \n",
    "    Directed_hashtags = SentimentHashtags[SentimentHashtags['Directed'] == i].copy() \n",
    "    Opp_hashtags = SentimentHashtags[SentimentHashtags['Directed'] != i].copy()\n",
    "    Opp_hashtags.loc[: ,'HashtagSentiment'] = Opp_hashtags.HashtagSentiment * -1;\n",
    "    Directed_hashtags = Directed_hashtags.append(Opp_hashtags)\n",
    "    \n",
    "    datasets[i] = pd.merge(datasets[i], Directed_hashtags, on = 'hashtags', how='outer')\n",
    "    datasets[i] = pd.merge(datasets[i], SentimentEmoji, on = 'emoticons', how='outer')\n",
    "    \n",
    "    sentiments_num = [-1, 0, 1]\n",
    "    HashtagsSentiments = []\n",
    "    EmoticonsSentiments = []\n",
    "    for senti in sentiments_num:\n",
    "        temp_hashtag = datasets[i][datasets[i].HashtagSentiment == senti]\n",
    "        temp_emoticon = datasets[i][datasets[i].Sentiment == senti]\n",
    "        temp_hashtag = temp_hashtag[['processed_text','HashtagSentiment']].dropna().groupby(['processed_text']).count().reset_index()\n",
    "        temp_hashtag.columns = ['processed_text','HashtagSentiment_'+str(senti)]\n",
    "        temp_emoticon = temp_emoticon[['processed_text','Sentiment']].dropna().groupby(['processed_text']).count().reset_index()\n",
    "        temp_emoticon.columns = ['processed_text','Sentiment_'+str(senti)]\n",
    "        HashtagsSentiments.append(temp_hashtag)\n",
    "        EmoticonsSentiments.append(temp_emoticon)\n",
    "    datasets[i] = pd.DataFrame(datasets[i]['processed_text'].unique())\n",
    "    datasets[i].columns = ['processed_text']\n",
    "    \n",
    "    for count in HashtagsSentiments:\n",
    "        datasets[i] = pd.merge(datasets[i], count, on='processed_text', how = 'outer')\n",
    "    for count in EmoticonsSentiments:\n",
    "        datasets[i] = pd.merge(datasets[i], count, on='processed_text', how = 'outer')\n",
    "    #TrainSets.append(datasets[i][['username', 'date', 'processed_text', 'Sentiment']].dropna().groupby(['processed_text', 'Sentiment']).max().reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets[0] = datasets[0].fillna(0)\n",
    "datasets[1] = datasets[1].fillna(0)\n",
    "def calculate_sentiment(row):\n",
    "    neg = row['HashtagSentiment_-1'] + row['Sentiment_-1']\n",
    "    neu = row.HashtagSentiment_0 + row.Sentiment_0\n",
    "    pos = row.HashtagSentiment_1 + row.Sentiment_1\n",
    "    if((neg == neu) and (neu == pos) and (pos == 0.0)):\n",
    "        return -2\n",
    "    if(neg > neu and neg > pos):\n",
    "        return -1\n",
    "    elif (neu > neg and neu > pos):\n",
    "        return 0\n",
    "    elif (pos > neg and pos > neu):\n",
    "        return 1\n",
    "    else:\n",
    "        return 3\n",
    "datasets[0]['finalSentiment'] = datasets[0].apply(calculate_sentiment, axis = 1)\n",
    "datasets[1]['finalSentiment'] = datasets[1].apply(calculate_sentiment, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to remember about the test dataset:\n",
    "1. They do not contain emoticons. We used all the tweets with emoticons for training as they were very less\n",
    "\n",
    "## Things to try out\n",
    "1. Use voting to find out the actual sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for Vectorizer: TF-IDF , Model: RandomForest 44 72\n",
      "The score for Vectorizer: TF-IDF , Model: Linear SVC 43 72\n",
      "The score for Vectorizer: TF-IDF with out ngram , Model: RandomForest 43 72\n",
      "The score for Vectorizer: TF-IDF with out ngram , Model: Linear SVC 44 72\n"
     ]
    }
   ],
   "source": [
    "print 'Prediction accuracy for Hillary'\n",
    "data_train = datasets[0][~((datasets[0].finalSentiment == 3) | (datasets[0].finalSentiment == -2))][['processed_text','finalSentiment']].copy().dropna()\n",
    "vectorizers = [TfidfVectorizer(stop_words=stop_list,ngram_range = (1,3)), TfidfVectorizer(stop_words=stop_list)]\n",
    "vectorizersName = ['TF-IDF', 'TF-IDF with out ngram']\n",
    "for k, vectorizer in enumerate(vectorizers):\n",
    "    X = vectorizer.fit_transform(data_train.processed_text.append(hillaryTest.processed_text))\n",
    "    X_train = X[0:data_train.processed_text.shape[0]]\n",
    "    Y_train = data_train['finalSentiment']\n",
    "    X_test = X[data_train.processed_text.shape[0]:]\n",
    "    models = [RandomForestClassifier(),LinearSVC()]\n",
    "    modelsName = ['RandomForest','Linear SVC']\n",
    "    for m, model in enumerate(models):\n",
    "        model.fit(X_train, Y_train)\n",
    "        preds = model.predict(X_test.todense())\n",
    "        score = 0\n",
    "        tot = 0\n",
    "        for i, pred in enumerate(preds):\n",
    "            if(hillaryTest.Sentiment[i] == hillaryTest.Sentiment[i]):\n",
    "                tot+=1\n",
    "                if(hillaryTest.Sentiment[i] == pred):\n",
    "                    score+=1\n",
    "\n",
    "        print 'The score for Vectorizer:', vectorizersName[k],', Model:', modelsName[m], score, tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for Vectorizer: TF-IDF , Model: RandomForest 40 68\n",
      "The score for Vectorizer: TF-IDF , Model: Linear SVC 43 68\n",
      "The score for Vectorizer: TF-IDF with out ngram , Model: RandomForest 40 68\n",
      "The score for Vectorizer: TF-IDF with out ngram , Model: Linear SVC 47 68\n"
     ]
    }
   ],
   "source": [
    "print 'Prediction accuracy for Donald Trump'\n",
    "data_train = datasets[1][~((datasets[1].finalSentiment == 3) | (datasets[1].finalSentiment == -2))][['processed_text','finalSentiment']].copy().dropna()\n",
    "vectorizers = [TfidfVectorizer(stop_words=stop_list,ngram_range = (1,3)), TfidfVectorizer(stop_words=stop_list)]\n",
    "vectorizersName = ['TF-IDF', 'TF-IDF with out ngram']\n",
    "for k, vectorizer in enumerate(vectorizers):\n",
    "    X = vectorizer.fit_transform(data_train.processed_text.append(TrumpTest.processed_text))\n",
    "    X_train = X[0:data_train.processed_text.shape[0]]\n",
    "    Y_train = data_train['finalSentiment']\n",
    "    X_test = X[data_train.processed_text.shape[0]:]\n",
    "    models = [RandomForestClassifier(),LinearSVC()]\n",
    "    modelsName = ['RandomForest','Linear SVC']\n",
    "    for m, model in enumerate(models):\n",
    "        model.fit(X_train, Y_train)\n",
    "        preds = model.predict(X_test.todense())\n",
    "        score = 0\n",
    "        tot = 0\n",
    "        for i, pred in enumerate(preds):\n",
    "            if(TrumpTest.Sentiment[i] == TrumpTest.Sentiment[i]):\n",
    "                tot+=1\n",
    "                if(TrumpTest.Sentiment[i] == pred):\n",
    "                    score+=1\n",
    "\n",
    "        print 'The score for Vectorizer:', vectorizersName[k],', Model:', modelsName[m], score, tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from gensim.models import word2vec\n",
    "\n",
    "def get_words(tweet):\n",
    "    return tweet.split(' ')\n",
    "tweets = pd.Series(data['processed_text'].unique()).apply(get_words)\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 140    # Word vector dimensionality                      \n",
    "min_word_count = 10   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "\n",
    "print \"Training model...\"\n",
    "model = word2vec.Word2Vec(tweets, workers=num_workers, size=num_features, min_count = min_word_count, window = context,\n",
    "                          sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"30features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for Vectorizer: TF-IDF Model: Linear SVC 43 68\n"
     ]
    }
   ],
   "source": [
    "lin_clf = LinearSVC()\n",
    "lin_clf.fit(X_train, Y_train) \n",
    "preds = lin_clf.predict(X_test.todense())\n",
    "score = 0\n",
    "tot = 0\n",
    "for i, pred in enumerate(preds):\n",
    "    if(TrumpTest.Sentiment[i] == TrumpTest.Sentiment[i]):\n",
    "        tot+=1\n",
    "    if(TrumpTest.Sentiment[i] == pred):\n",
    "        score+=1\n",
    "\n",
    "print 'The score for Vectorizer: TF-IDF', 'Model: Linear SVC', score, tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.,  0.,  2.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainSets[1].Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Sentiments_num = [-1]\n",
    "\n",
    "temp\n",
    "for senti in Sentiments_num:\n",
    "    temp = datasets[0][datasets[0].HashtagSentiment == senti]\n",
    "    temp = temp[['processed_text','HashtagSentiment']].dropna().groupby(['processed_text']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_text</th>\n",
       "      <th>HashtagSentiment_-1</th>\n",
       "      <th>HashtagSentiment_0</th>\n",
       "      <th>HashtagSentiment_1</th>\n",
       "      <th>Sentiment_-1</th>\n",
       "      <th>Sentiment_0</th>\n",
       "      <th>Sentiment_1</th>\n",
       "      <th>finalSentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>donald trump open new line of attack on hillar...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>in viral post, entire star trek cast begs amer...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>gary johnson sound more reasonable in these 5 ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>the joker resembles more of donald trump than ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>hillary ha nothing to run</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>spread this now! hillary in panic mode video o...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>hillary clinton is 'nasty, but i can be nastie...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>i honestly thought it would take more than 90 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>you're voting for a man who steal from vets, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>hillary is nasty, but trump promise he is nast...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>relnews: donald trump attack hillary clinton o...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>if donald trump win i'm moving to canada if hi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>voter at trump rally are excited because they ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>donald trump go after the clintons' marital hi...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>trump demand that obama not pardon hillary ! t...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>dont like trump but calling him old when hil...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>hillary clintonâs remark on young voter fuel...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tell me how hillary is polling equal to trump ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>if all the bernie supporter voted for hillary ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>hillary already showed u she flip once electe...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>i'll say it again, call hillary a liar, a phon...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>is hillary clinton right that donald trump ha ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>donald trump go after the clintons' marital hi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>are you looking forward to seeing trump 's ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>this moron is attempting to draw the comparis...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>bill clinton got aid from messing around with ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>hillary for america release new video on trump...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>hillary clinton present her vision a she call ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>if trump back out of the remaining debates, i ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>relnews: hillary clinton, donald trump face of...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13143</th>\n",
       "      <td>donald trump : hillary clinton should return t...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13144</th>\n",
       "      <td>best minds\"? illusional,factual or corruptible...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13146</th>\n",
       "      <td>hillary : \" trump said horrible</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13160</th>\n",
       "      <td>nevertrump republican should really consider ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13166</th>\n",
       "      <td>vote trump never hillary  makeamericagreatagain</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13167</th>\n",
       "      <td>hey everyone check your facebook website on bo...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13169</th>\n",
       "      <td>trumptrain breaking: whoops!! hillary clinton...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13170</th>\n",
       "      <td>trumptrain video : russia warns americans, \"v...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13178</th>\n",
       "      <td>i'm a diehard republican &amp; i despise hillary w...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13242</th>\n",
       "      <td>hillary trump putin netanyahu final betting ch...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13243</th>\n",
       "      <td>girl on news: i know trump is horribly racist ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13244</th>\n",
       "      <td>good video  i feel kinda the same, i guess i'...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13245</th>\n",
       "      <td>.  i dont think trump need more ad (except to ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13246</th>\n",
       "      <td>with trump we have an apocalypse and hillary w...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13247</th>\n",
       "      <td>rt for trump and like for hillary</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13248</th>\n",
       "      <td>this election, i do not care trump or hillary ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13249</th>\n",
       "      <td>creo que me voy a perder el segundo debate ent...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13250</th>\n",
       "      <td>hillary with her losing ass,,lied on trump ,,a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13251</th>\n",
       "      <td>im fighting hard for trump !! yes, for our n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13252</th>\n",
       "      <td>but trump and hillary</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13253</th>\n",
       "      <td>le scary than trump / hillary !   halloweenin5...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13254</th>\n",
       "      <td>the one i know just detest hillary and they a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13255</th>\n",
       "      <td>donald trump : \" hillary is a great friend of ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13256</th>\n",
       "      <td>and the trump supporter will say \"but what abo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13257</th>\n",
       "      <td>hillary &amp;  billclinton reallyscrewedovertheha...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13258</th>\n",
       "      <td>suchhypocrisy   trumpsarmy  trumptrain  always...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13259</th>\n",
       "      <td>it rhonchi, but guy locker talk  i can handle...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13260</th>\n",
       "      <td>no, if you look at the picture, he's voting ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13261</th>\n",
       "      <td>wellyourstuckwithhimnow  hillary   trumpsarmy ...</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13263</th>\n",
       "      <td>thanks obama! you &amp; hillary caused this?  youï...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1563 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          processed_text  HashtagSentiment_-1  \\\n",
       "21     donald trump open new line of attack on hillar...                  7.0   \n",
       "34     in viral post, entire star trek cast begs amer...                  1.0   \n",
       "43     gary johnson sound more reasonable in these 5 ...                  4.0   \n",
       "51     the joker resembles more of donald trump than ...                  8.0   \n",
       "80                            hillary ha nothing to run                   1.0   \n",
       "85     spread this now! hillary in panic mode video o...                  0.0   \n",
       "87     hillary clinton is 'nasty, but i can be nastie...                  1.0   \n",
       "93     i honestly thought it would take more than 90 ...                  1.0   \n",
       "98      you're voting for a man who steal from vets, ...                  0.0   \n",
       "109    hillary is nasty, but trump promise he is nast...                  1.0   \n",
       "136    relnews: donald trump attack hillary clinton o...                  4.0   \n",
       "148    if donald trump win i'm moving to canada if hi...                  2.0   \n",
       "153    voter at trump rally are excited because they ...                  1.0   \n",
       "160    donald trump go after the clintons' marital hi...                  3.0   \n",
       "162    trump demand that obama not pardon hillary ! t...                  4.0   \n",
       "172      dont like trump but calling him old when hil...                  0.0   \n",
       "178    hillary clintonâs remark on young voter fuel...                  0.0   \n",
       "191    tell me how hillary is polling equal to trump ...                  2.0   \n",
       "193    if all the bernie supporter voted for hillary ...                  2.0   \n",
       "195     hillary already showed u she flip once electe...                  0.0   \n",
       "241    i'll say it again, call hillary a liar, a phon...                  2.0   \n",
       "252    is hillary clinton right that donald trump ha ...                  1.0   \n",
       "261    donald trump go after the clintons' marital hi...                  1.0   \n",
       "267       are you looking forward to seeing trump 's ...                  1.0   \n",
       "268     this moron is attempting to draw the comparis...                  1.0   \n",
       "271    bill clinton got aid from messing around with ...                  5.0   \n",
       "276    hillary for america release new video on trump...                  6.0   \n",
       "287    hillary clinton present her vision a she call ...                 10.0   \n",
       "307    if trump back out of the remaining debates, i ...                  1.0   \n",
       "319    relnews: hillary clinton, donald trump face of...                  1.0   \n",
       "...                                                  ...                  ...   \n",
       "13143  donald trump : hillary clinton should return t...                  2.0   \n",
       "13144  best minds\"? illusional,factual or corruptible...                  2.0   \n",
       "13146                   hillary : \" trump said horrible                   4.0   \n",
       "13160   nevertrump republican should really consider ...                  0.0   \n",
       "13166   vote trump never hillary  makeamericagreatagain                   2.0   \n",
       "13167  hey everyone check your facebook website on bo...                  2.0   \n",
       "13169   trumptrain breaking: whoops!! hillary clinton...                  2.0   \n",
       "13170   trumptrain video : russia warns americans, \"v...                  2.0   \n",
       "13178  i'm a diehard republican & i despise hillary w...                  2.0   \n",
       "13242  hillary trump putin netanyahu final betting ch...                  0.0   \n",
       "13243  girl on news: i know trump is horribly racist ...                  0.0   \n",
       "13244   good video  i feel kinda the same, i guess i'...                  0.0   \n",
       "13245  .  i dont think trump need more ad (except to ...                  0.0   \n",
       "13246  with trump we have an apocalypse and hillary w...                  0.0   \n",
       "13247                rt for trump and like for hillary                    0.0   \n",
       "13248  this election, i do not care trump or hillary ...                  0.0   \n",
       "13249  creo que me voy a perder el segundo debate ent...                  0.0   \n",
       "13250  hillary with her losing ass,,lied on trump ,,a...                  0.0   \n",
       "13251    im fighting hard for trump !! yes, for our n...                  0.0   \n",
       "13252                             but trump and hillary                   0.0   \n",
       "13253  le scary than trump / hillary !   halloweenin5...                  2.0   \n",
       "13254   the one i know just detest hillary and they a...                  0.0   \n",
       "13255  donald trump : \" hillary is a great friend of ...                  0.0   \n",
       "13256  and the trump supporter will say \"but what abo...                  0.0   \n",
       "13257   hillary &  billclinton reallyscrewedovertheha...                 16.0   \n",
       "13258  suchhypocrisy   trumpsarmy  trumptrain  always...                 20.0   \n",
       "13259   it rhonchi, but guy locker talk  i can handle...                  0.0   \n",
       "13260    no, if you look at the picture, he's voting ...                  0.0   \n",
       "13261  wellyourstuckwithhimnow  hillary   trumpsarmy ...                161.0   \n",
       "13263  thanks obama! you & hillary caused this?  youï...                  0.0   \n",
       "\n",
       "       HashtagSentiment_0  HashtagSentiment_1  Sentiment_-1  Sentiment_0  \\\n",
       "21                    0.0                 0.0           0.0          0.0   \n",
       "34                    0.0                 0.0           0.0          0.0   \n",
       "43                    0.0                 0.0           0.0          0.0   \n",
       "51                    0.0                 0.0           0.0          0.0   \n",
       "80                    0.0                 0.0           0.0          0.0   \n",
       "85                    0.0                 6.0           0.0          0.0   \n",
       "87                    0.0                 0.0           0.0          0.0   \n",
       "93                    0.0                 0.0           0.0          0.0   \n",
       "98                    0.0                 6.0           0.0          0.0   \n",
       "109                   0.0                 0.0           0.0          0.0   \n",
       "136                   0.0                 0.0           0.0          0.0   \n",
       "148                   0.0                 0.0           0.0          0.0   \n",
       "153                   0.0                 0.0           0.0          0.0   \n",
       "160                   0.0                 0.0           0.0          0.0   \n",
       "162                   0.0                 0.0           0.0          0.0   \n",
       "172                   0.0                 1.0           0.0          0.0   \n",
       "178                   0.0                14.0           0.0          0.0   \n",
       "191                   0.0                 0.0           0.0          0.0   \n",
       "193                   0.0                 0.0           0.0          0.0   \n",
       "195                   0.0                 2.0           0.0          0.0   \n",
       "241                   0.0                 0.0           0.0          0.0   \n",
       "252                   0.0                 0.0           0.0          0.0   \n",
       "261                   0.0                 0.0           0.0          0.0   \n",
       "267                   0.0                 0.0           0.0          0.0   \n",
       "268                   0.0                 0.0           0.0          0.0   \n",
       "271                   0.0                 0.0           0.0          0.0   \n",
       "276                   0.0                 0.0           0.0          0.0   \n",
       "287                   0.0                 1.0           0.0          0.0   \n",
       "307                   0.0                 0.0           0.0          0.0   \n",
       "319                   0.0                 0.0           0.0          0.0   \n",
       "...                   ...                 ...           ...          ...   \n",
       "13143                 0.0                 0.0           0.0          0.0   \n",
       "13144                 0.0                 0.0           0.0          0.0   \n",
       "13146                 0.0                 0.0           0.0          0.0   \n",
       "13160                 0.0                 2.0           0.0          0.0   \n",
       "13166                 0.0                 0.0           0.0          0.0   \n",
       "13167                 0.0                 0.0           0.0          0.0   \n",
       "13169                 0.0                 0.0           0.0          0.0   \n",
       "13170                 0.0                 0.0           0.0          0.0   \n",
       "13178                 0.0                 0.0           0.0          0.0   \n",
       "13242                 0.0                 0.0           0.0          0.0   \n",
       "13243                 0.0                 0.0           0.0          0.0   \n",
       "13244                 0.0                 0.0           0.0          0.0   \n",
       "13245                 0.0                 0.0           0.0          0.0   \n",
       "13246                 0.0                 0.0           0.0          0.0   \n",
       "13247                 0.0                 0.0           0.0          0.0   \n",
       "13248                 0.0                 0.0           0.0          0.0   \n",
       "13249                 0.0                 0.0           1.0          0.0   \n",
       "13250                 0.0                 0.0           1.0          0.0   \n",
       "13251                 0.0                 0.0           1.0          0.0   \n",
       "13252                 0.0                 0.0           1.0          0.0   \n",
       "13253                 0.0                 0.0           4.0          0.0   \n",
       "13254                 0.0                 0.0           4.0          0.0   \n",
       "13255                 0.0                 0.0           0.0          0.0   \n",
       "13256                 0.0                 0.0           1.0          0.0   \n",
       "13257                 0.0                 0.0          64.0          0.0   \n",
       "13258                 0.0                 0.0         100.0          0.0   \n",
       "13259                 0.0                 0.0           0.0          1.0   \n",
       "13260                 0.0                 0.0           0.0          0.0   \n",
       "13261                 0.0                 0.0           0.0          0.0   \n",
       "13263                 0.0                 4.0           0.0          0.0   \n",
       "\n",
       "       Sentiment_1  finalSentiment  \n",
       "21             0.0              -1  \n",
       "34             0.0              -1  \n",
       "43             0.0              -1  \n",
       "51             0.0              -1  \n",
       "80             0.0              -1  \n",
       "85             0.0               1  \n",
       "87             0.0              -1  \n",
       "93             0.0              -1  \n",
       "98             0.0               1  \n",
       "109            0.0              -1  \n",
       "136            0.0              -1  \n",
       "148            0.0              -1  \n",
       "153            0.0              -1  \n",
       "160            0.0              -1  \n",
       "162            0.0              -1  \n",
       "172            0.0               1  \n",
       "178            0.0               1  \n",
       "191            0.0              -1  \n",
       "193            0.0              -1  \n",
       "195            0.0               1  \n",
       "241            0.0              -1  \n",
       "252            0.0              -1  \n",
       "261            0.0              -1  \n",
       "267            0.0              -1  \n",
       "268            0.0              -1  \n",
       "271            0.0              -1  \n",
       "276            0.0              -1  \n",
       "287            0.0              -1  \n",
       "307            0.0              -1  \n",
       "319            0.0              -1  \n",
       "...            ...             ...  \n",
       "13143          0.0              -1  \n",
       "13144          0.0              -1  \n",
       "13146          0.0              -1  \n",
       "13160          0.0               1  \n",
       "13166          0.0              -1  \n",
       "13167          0.0              -1  \n",
       "13169          0.0              -1  \n",
       "13170          0.0              -1  \n",
       "13178          0.0              -1  \n",
       "13242          1.0               1  \n",
       "13243          1.0               1  \n",
       "13244          1.0               1  \n",
       "13245          1.0               1  \n",
       "13246          1.0               1  \n",
       "13247          4.0               1  \n",
       "13248          1.0               1  \n",
       "13249          0.0              -1  \n",
       "13250          0.0              -1  \n",
       "13251          0.0              -1  \n",
       "13252          0.0              -1  \n",
       "13253          0.0              -1  \n",
       "13254          0.0              -1  \n",
       "13255          1.0               1  \n",
       "13256          0.0              -1  \n",
       "13257          0.0              -1  \n",
       "13258          0.0              -1  \n",
       "13259          0.0               0  \n",
       "13260          1.0               1  \n",
       "13261        529.0               1  \n",
       "13263          0.0               1  \n",
       "\n",
       "[1563 rows x 8 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0][~((datasets[0].finalSentiment == 3) | (datasets[0].finalSentiment == -2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
